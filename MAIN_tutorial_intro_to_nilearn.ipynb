{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import nilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's keep our notebook clean, so it's a little more readable!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Understanding neuroimaging data](http://nilearn.github.io/manipulating_images/input_output.html)\n",
    "\n",
    "### Text files: phenotype or behavior\n",
    "\n",
    "Phenotypic or behavioral data are often provided as text or CSV (Comma Separated Values) file. They can be loaded with the [pandas package](https://pandas.pydata.org/) but you may have to specify some options. Here, we'll specify the `sep` field, since our data is tab-delimited rather than comma-delimited.\n",
    "\n",
    "For our dataset, let's load participant level information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = '/home/Desktop/MAIN_tutorial/'\n",
    "participants = 'participants.tsv'\n",
    "phenotypic_data = pd.read_csv(os.path.join(data_dir, participants), sep='\\t')\n",
    "phenotypic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nifti data\n",
    "\n",
    "For volumetric data, nilearn works with data stored in the [Nifti structure](http://nipy.org/nibabel/nifti_images.html) (via the [nibabel package](http://nipy.org/nibabel/)).\n",
    "\n",
    "The NifTi data structure (also used in Analyze files) is the standard way of sharing data in neuroimaging research. Three main components are:\n",
    "\n",
    "  * data:\traw scans in form of a numpy array:  \n",
    "    `data = img.get_data()`\n",
    "  * affine:\treturns the transformation matrix that maps from voxel indices of the `numpy` array to actual real-world     locations of the brain:  \n",
    "    `affine = img.affine`\n",
    "  * header:\tlow-level informations about the data (slice duration, etc.):  \n",
    "  `header = img.header`\n",
    "\n",
    "It is important to appreciate that the representation of MRI data we'll be using is a big 4D matrix representing (3D MRI + 1D for time), stored in a single Nifti file.\n",
    "\n",
    "### Niimg-like objects\n",
    "\n",
    "Nilearn functions take as input argument what we call \"Niimg-like objects\":\n",
    "\n",
    "Niimg: A Niimg-like object can be one of the following:\n",
    "\n",
    "  * A string with a file path to a Nifti image\n",
    "  * An SpatialImage from `nibabel`, ie an object exposing get_data() method and affine attribute, typically a Nifti1Image from `nibabel`.\n",
    "\n",
    "Niimg-4D: Similarly, some functions require 4D Nifti-like data, which we call Niimgs or Niimg-4D. Accepted input arguments are:\n",
    "\n",
    "  * A path to a 4D Nifti image\n",
    "  * List of paths to 3D Nifti images\n",
    "  * 4D Nifti-like object\n",
    "  * List of 3D Nifti-like objects\n",
    "\n",
    "**Note:** If you provide a sequence of Nifti images, all of them must have the same affine !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Manipulating and looking at data](http://nilearn.github.io/auto_examples/plot_nilearn_101.html#sphx-glr-auto-examples-plot-nilearn-101-py)\n",
    "\n",
    "There is a whole section of the [Nilearn documentation](http://nilearn.github.io/plotting/index.html#plotting) on making pretty plots for neuroimaging data ! But let's start with a simple one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use a Nifti file that is shipped with nilearn\n",
    "from nilearn import datasets\n",
    "\n",
    "# Note that the variable MNI152_FILE_PATH is just a path to a Nifti file\n",
    "print('Path to MNI152 template: {}'.format(datasets.MNI152_FILE_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, MNI152_FILE_PATH is nothing more than a string with a path pointing to a nifti image. You can replace it with a string pointing to a file on your disk. Note that it should be a 3D volume, and not a 4D volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "plotting.view_img(datasets.MNI152_FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also directly manipulate these images using Nilearn ! As an example, let's try smoothing this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "smooth_anat_img = image.smooth_img(datasets.MNI152_FILE_PATH, fwhm=6)\n",
    "\n",
    "# While we are giving a file name as input, the function returns\n",
    "# an in-memory object:\n",
    "print(smooth_anat_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.view_img(smooth_anat_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then save this manipulated image from in-memory to disk as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_anat_img.to_filename('smooth_anat_img.nii.gz')\n",
    "os.getcwd()  # We'll' check our \"current working directory\" (cwd) to see where the file was saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Convert the fMRI volumes to a data matrix](http://nilearn.github.io/auto_examples/plot_decoding_tutorial.html#convert-the-fmri-volume-s-to-a-data-matrix)\n",
    "\n",
    "These are some really lovely images, but for machine learning we want matrices ! Then we can use all of the techniques we learned this morning.\n",
    "\n",
    "To transform our Nifti images into matrices, we'll use the `nilearn.input_data.NiftiMasker` to extract the fMRI data using a parcellation and convert it to data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's load a parcellation that we'd like to use\n",
    "multiscale = datasets.fetch_atlas_basc_multiscale_2015()\n",
    "plotting.plot_roi(multiscale.scale064)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "masker = NiftiLabelsMasker(labels_img=multiscale.scale064, standardize=True)\n",
    "masker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We give the masker a filename and retrieve a 2D array ready\n",
    "# for machine learning with scikit-learn !\n",
    "fmri_filename = 'downsampled_derivatives:fmriprep:sub-pixar001:sub-pixar001_task-pixar_run-001_swrf_bold.nii.gz'\n",
    "fmri_matrix = masker.fit_transform(os.path.join(data_dir, fmri_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fmri_masked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
